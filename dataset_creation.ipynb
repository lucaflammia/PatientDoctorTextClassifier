{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATIENT - DOCTOR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Postzeun/Patient-Doctor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines = dataset['train']['text']\n",
    "\n",
    "data = {'text': [], 'label': []}\n",
    "\n",
    "patient_text = []\n",
    "doctor_text = []\n",
    "\n",
    "for line in text_lines:\n",
    "  if line.startswith('P:'):\n",
    "    line = line.replace('P:', '').strip()\n",
    "    label = 0\n",
    "    patient_text.append(line)\n",
    "  elif line.startswith('D:'):\n",
    "    line = line.replace('D:', '').strip()\n",
    "    label = 1\n",
    "    doctor_text.append(line)\n",
    "  else:\n",
    "    continue\n",
    "  data['text'].append(line)\n",
    "  data['label'].append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'text': data['text'], 'label': data['label']})\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_PATH = os.getcwd()\n",
    "df2 = pd.read_csv(os.path.join(PROJECT_PATH, 'dataset/pulsar_contents.csv'))\n",
    "df2.rename(columns={\"bio\": \"text\"}, inplace=True)\n",
    "df2['label'] = 2\n",
    "df2 = df2[['text', 'label']]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With three labels P - D - N\n",
    "frames = [df1, df2]\n",
    "\n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.isna(df['text']).value_counts()\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check non-latin characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATIN_1_CHARS = (\n",
    "    ('\\xe2\\x80\\x99', \"'\"),\n",
    "    ('\\xc3\\xa9', 'e'),\n",
    "    ('\\xe2\\x80\\x90', '-'),\n",
    "    ('\\xe2\\x80\\x91', '-'),\n",
    "    ('\\xe2\\x80\\x92', '-'),\n",
    "    ('\\xe2\\x80\\x93', '-'),\n",
    "    ('\\xe2\\x80\\x94', '-'),\n",
    "    ('\\xe2\\x80\\x94', '-'),\n",
    "    ('\\xe2\\x80\\x98', \"'\"),\n",
    "    ('\\xe2\\x80\\x9b', \"'\"),\n",
    "    ('\\xe2\\x80\\x9c', '\"'),\n",
    "    ('\\xe2\\x80\\x9c', '\"'),\n",
    "    ('\\xe2\\x80\\x9d', '\"'),\n",
    "    ('\\xe2\\x80\\x9e', '\"'),\n",
    "    ('\\xe2\\x80\\x9f', '\"'),\n",
    "    ('\\xe2\\x80\\xa6', '...'),\n",
    "    ('\\xe2\\x80\\xb2', \"'\"),\n",
    "    ('\\xe2\\x80\\xb3', \"'\"),\n",
    "    ('\\xe2\\x80\\xb4', \"'\"),\n",
    "    ('\\xe2\\x80\\xb5', \"'\"),\n",
    "    ('\\xe2\\x80\\xb6', \"'\"),\n",
    "    ('\\xe2\\x80\\xb7', \"'\"),\n",
    "    ('\\xe2\\x81\\xba', \"+\"),\n",
    "    ('\\xe2\\x81\\xbb', \"-\"),\n",
    "    ('\\xe2\\x81\\xbc', \"=\"),\n",
    "    ('\\xe2\\x81\\xbd', \"(\"),\n",
    "    ('\\xe2\\x81\\xbe', \")\")\n",
    ")\n",
    "\n",
    "\n",
    "def clean_latin1(data):\n",
    "    try:\n",
    "        return data.encode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        data = data.decode('iso-8859-1')\n",
    "        for _hex, _char in LATIN_1_CHARS:\n",
    "            data = data.replace(_hex, _char)\n",
    "        return data.encode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for text in df['text'].values:\n",
    "  try:\n",
    "    text = clean_latin1(text)\n",
    "    # text.encode(encoding='utf-8').decode('ascii')\n",
    "  except:\n",
    "    print(f'error for {text}')\n",
    "    error.append(text)\n",
    "  # text.encode(encoding='utf-8').decode('ascii')\n",
    "\n",
    "print(len(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Classification Score Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=f\"{HF_USERNAME}/{TASK}\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_list = []\n",
    "for text in dataset['test']['Text']:\n",
    "  res = classifier(text)\n",
    "  pred_score_list.append(res[0])\n",
    "\n",
    "df_test['Classification Score'] = pred_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Classification Score'] = [[{'label': 'PATIENT', 'score': float(0)}, {'label': 'DOCTOR', 'score': float(0)}, {'label': 'NEUTRAL', 'score': float(0)}]] * len(df_train.index)\n",
    "df_val['Classification Score'] = [[{'label': 'PATIENT', 'score': float(0)}, {'label': 'DOCTOR', 'score': float(0)}, {'label': 'NEUTRAL', 'score': float(0)}]] * len(df_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_USERNAME = \"LukeGPT88\"\n",
    "PROJECT_NAME = \"patient-doctor-text-classifier\"\n",
    "SUB_PROJECT_NAME = \"eng\"\n",
    "DATASET_NAME = f\"{HF_USERNAME}/{PROJECT_NAME}-{SUB_PROJECT_NAME}-dataset-0528\"\n",
    "TASK = f\"{PROJECT_NAME}-{SUB_PROJECT_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/luca/Documents/Extendi/ML/Extendi/AIProjects/TextClassification/PatientDoctorTextClassifier/Dataframes/20240528'\n",
    "df = pd.read_csv(f'{folder_path}/df_tot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = \\\n",
    "              np.split(df.sample(frac=1, random_state=42).reset_index(drop=True), \n",
    "                       [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train)\n",
    "validation_ds = Dataset.from_pandas(validate)\n",
    "test_ds = Dataset.from_pandas(test)\n",
    "\n",
    "ddict = DatasetDict({\n",
    "    \"train\": train_ds,   # split1_ds is an instance of `datasets.Dataset`\n",
    "    \"validation\": validation_ds,\n",
    "    \"test\": test_ds,\n",
    "})\n",
    "ddict.push_to_hub(DATASET_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
